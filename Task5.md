Advanced topics in web development 2 Yonis Ismail
Task 5
Visualisation of the data has been done using the Google maps API, more specifically the JavaScript version of the Google maps API. To obtain the data, the program will read through the csv files to find the latitude and longitude of each site and then map those coordinates onto the map. However, as site 481 does not have any data in the csv file for that site, the coordinates have been hard coded in the program.
Extending the visualisation of the data has been also done by Google maps API, as the markers have a purpose other than to point out the exact location of a site. By clicking on the markers, it will open up a link which will allow users to be directed onto another site which will contain further data about each site, therefore allowing users to get more information about how the air pollution in the area is. There is also the use of the Flickr API, which will allow users to view images of each site or the surrounding area, in order to have a clearer image on how each area will look like.
SimpleXML in a DOM based parser which acts as an extension in PHP to allow for simple manipulation of XML data, such as converting data into XML data. XMLReader is another parser however XMLReader is a stream-oriented parser which acts as a cursor going forward a document and it stops at each node. XMLReader is faster and uses little memory compared to SimpleXML and other DOM based parsers however it is much harder to write and debug therefore it can be prone to many errors compared to SimpleXML, this is the reason why I have chosen to use DOM based parsers for my implementation to write XML files.
For the first two learning outcome, I have clearly demonstrated the ability to model, cleanse and normalise substantial real-world big data and data cleaning for converting the data into smaller CSV files which have been cleaned. However, the second part of the second learning objective is about normalised XML files which I have not demonstrated as currently my XML files have repeated data, however I will continue to improve my skills on normalising XML files in the future. I have also shown clear knowledge and skill in designing, implementing and visualising data using web-based charting and mapping APIs which can be shown within my submission. However, it is clear that I needed to little more time with the line chart as it is definitely within my capabilities as show in the code, but it needed just a little extra time for a full implementation.
Going forward, I will definitely work upon my skills in normalising XML files and time management on my web-based charting however I have shown strong understanding of PHP, XML, XSD, JavaScript, JSON and parsing. This can be shown in the two conversion scripts for benchmarking and the XSD schema file to validate my XML files. 
 
[Air-quality XSD file](air-quality.xsd)

[Extract to CSV](extract-to-csv.php)

[Task 3 Charts](Task3main.html)

[Task 4 Visualisation](Task4.php)

